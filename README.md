## Введение

В рамках данной лабораторной работы был проведен анализ корпуса текстовых данных из социальной сети Twitter. Основной целью было изучение структуры данных, первичный анализ, а также применение методов обработки естественного языка для подготовки данных к дальнейшему анализу.

#### Исходные данные

Корпус данных представляет собой набор записей из социальной сети Twitter.
##### Основные поля данных:
– id: уникальный номер сообщения в системе twitter;
– tdate: дата публикации сообщения (твита);
– tmane: имя пользователя, опубликовавшего сообщение;
– ttext: текст сообщения (твита);
– ttype: поле в котором в дальнейшем будет указано к кому классу относится твит
(положительный, отрицательный);
– trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не
отдает эту информацию;
– tfav: число сколько раз данное сообщение было добавлено в избранное другими
пользователями;
– tstcount: число всех сообщений пользователя в сети twitter;
– tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);
– tfrien: количество друзей пользователя (те люди, которых читает пользователь);
– listcount: количество листов-подписок в которые добавлен твиттер-пользователь.

## Этапы анализа

##### Загрузка и объединение данных: 
Данные были загружены из двух файлов и объединены в один DataFrame для удобства анализа.

##### Предварительный анализ: 
Был проведен анализ основных статистических показателей DataFrame, включая распределение основных метрик, таких как количество фоловеров, друзей и других.

##### Подготовка текстовых данных: 
Для анализа текстовых данных были использованы следующие методы:

1. Токенизация: разбиение текста на отдельные слова или токены.
2. Лемматизация: приведение слов к их начальной форме.
3. Удаление стоп-слов: очистка текста от общеупотребительных слов, не несущих смысловой нагрузки для анализа.
4. Векторизация текстов: Для преобразования текстовых данных в числовую форму были использованы два метода:

  
* Bag of Words (BoW): представление текста в виде вектора на основе частоты встречаемости слов.

* TF-IDF: учет не только частоты встречаемости слова в конкретном тексте, но и его уникальности для всего корпуса данных.

Сохранение результатов: После обработки и векторизации данных результаты были сохранены в отдельные файлы для возможности их дальнейшего использования.

## Заключение

В ходе проведения лабораторной работы были освоены основные методы предобработки и анализа текстовых данных. Полученные результаты могут стать основой для дальнейших исследований, например, по классификации твитов по настроению или анализу популярности определенных тем в социальной сети Twitter.